{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI8zd7hu0EXWZ+Ky9m6MrY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rony31416/Topic-Modeling-Using-NMF/blob/main/BanglaNLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "luiZHELuylph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## use **`!pip freeze`** for installed packages"
      ],
      "metadata": {
        "id": "l13MxAb4yn6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "FCJpM_1llMcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LKWa_th67krz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't Why **bnltk** is not working! So let's install **`banglanltk`** pakage\n",
        "using **$ `pip install banglanltk`**"
      ],
      "metadata": {
        "id": "bCCf2mmczXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install banglanltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu5Uc1LMnPsM",
        "outputId": "8cb97dca-8d06-46de-85f2-34ed141d557f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting banglanltk\n",
            "  Downloading banglanltk-0.0.4-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: banglanltk\n",
            "Successfully installed banglanltk-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1OTL59NzFef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Cleaning Text**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Import the **`banglanltk`** library as **`bn`**.\n",
        "\n",
        "2. Called a function named **`clean_text`** that takes a **`Bangla string`** as input.\n",
        "\n",
        "3. Inside the function, define a list of Bangla punctuation marks to be removed.\n",
        "  \n",
        "```\n",
        "punctuation_marks = ['।', ',', '.', '?', '!', '…', ':', ';', '@', '#', '$', '^', '&', '*', '(', ')', '{', '}', '[', ']', \"'\", '‘', '’', '“', '”', '-', '_']\n",
        "```\n",
        "4. print the clean text after removing all **`punctuation_marks`**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NiuM8yxg4Ahu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import banglanltk as bn\n",
        "s = 'আমি খুব ভালো আছি! আমি কোনো সমস্যার সম্মুখে নেই? হয়তো থামে যাবে না()... আমি আপনাদের কাছে এসেছি: \"কেমন আছেন?\" এবং এটা দেখে আশা করছি - সবাই ভালোই আছেন!'\n",
        "\n",
        "print(bn.clean_text(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbwSV6P2022L",
        "outputId": "0fc2d191-bba7-4923-e0e4-5b7b83186d92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "আমি খুব ভালো আছি আমি কোনো সমস্যার সম্মুখে নেই হয়তো থামে যাবে না আমি আপনাদের কাছে এসেছি কেমন আছেন এবং এটা দেখে আশা করছি  সবাই ভালোই আছেন\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Tokenization**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Word tokenization is the process of breaking down a text into individual words or tokens.\n",
        "\n",
        "Firstly, we include the **`banglanltk`**  library and then call the function named **`word_tokenize()`** for tokenization.\n",
        "\n",
        "The **`word_tokenize()`** function uses the **`clean_text()`** function first and then separates the words individually."
      ],
      "metadata": {
        "id": "_Mc6FJQTsJTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import banglanltk as bn\n",
        "\n",
        "s = 'আমি বাংলায় লেখা একটি বাক্য,টোকেনাইজেশন করতে চাই। হ্যাঁ?'\n",
        "print(bn.word_tokenize(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWxhU15NpwQ5",
        "outputId": "c35cbebb-b292-4ec7-93c6-7b8f4f3c8613"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['আমি', 'বাংলায়', 'লেখা', 'একটি', 'বাক্যটোকেনাইজেশন', 'করতে', 'চাই', 'হ্যাঁ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentence Tokenization**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sentence tokenization is the process of breaking down a text into individual sentences. The objective is to identify and extract sentences from a given paragraph or document. This task is essential in natural language processing (NLP) and text analysis because many language processing applications operate at the sentence level.\n",
        "\n",
        "### The **`sent_tokenize()`** work with some steps:\n",
        "\n",
        "1. Remove the Punctuatios and replace tabs, newlines, and certain characters with spaces\n",
        "2. Replace multiple spaces with a single space.\n",
        "3.   Strip trailing । (Bengali full stop), ? and ! and split into sentences.\n",
        "4.   Filter out empty strings and return the list of sentences\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hNlatMd_xDke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import banglanltk as bn\n",
        "\n",
        "s = ''' আমি আজ শহরে গিয়েছি কিন্তু বৃষ্টি হয়নি। সবাইকে শুভ নববর্ষ! বাংলা ভাষায় কবিতা পড়তে খুব ভালো লাগে। বইগুলি বইমেলায় খুব সস্তায় পাওয়া যায়। '''\n",
        "print(bn.sent_tokenize(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAuajjjoxBtK",
        "outputId": "29f04819-9f67-4618-f526-ae5115f4c2d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['আমি আজ শহরে গিয়েছি কিন্তু বৃষ্টি হয়নি', 'সবাইকে শুভ নববর্ষ', 'বাংলা ভাষায় কবিতা পড়তে খুব ভালো লাগে', 'বইগুলি বইমেলায় খুব সস্তায় পাওয়া যায়']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**\n",
        "\n",
        "---\n",
        "\n",
        "Stemming in Bengali NLP (Natural Language Processing) refers to the process of reducing words to their root or base form, known as the \"stem.\" The purpose of stemming is to normalize words and group together variations of the same word, which helps in text analysis and information retrieval tasks.\n",
        "\n",
        "In the context of Bengali stemming, the goal is to transform different inflected forms or derived words into a common base or root form. This process involves removing suffixes or prefixes from words while keeping the core meaning intact. For example:\n",
        "\n",
        "খেলছি (playing) → খেল (play),\n",
        "খাচ্ছে (eating) → খাও (eat),\n",
        "বলছে (speaking) → বল (speak)\n",
        "\n"
      ],
      "metadata": {
        "id": "_4D1pbyI299b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import banglanltk as bn\n",
        "\n",
        "# For single word\n",
        "print(bn.stemmer('বলছে'))\n",
        "\n",
        "# For sentence\n",
        "text = 'আমি আজ শহরে গিয়েছি কিন্তু বৃষ্টি হয়নি'\n",
        "words = bn.word_tokenize(text)\n",
        "for w in words:\n",
        "    print(bn.stemmer(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBFAmao2285T",
        "outputId": "0dd8ab6e-d2e2-4dd3-ac2c-574027e1250b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "বল\n",
            "আমি\n",
            "আজ\n",
            "শহর\n",
            "গ\n",
            "কিন্তু\n",
            "বৃষ্টি\n",
            "হয়নি\n"
          ]
        }
      ]
    }
  ]
}